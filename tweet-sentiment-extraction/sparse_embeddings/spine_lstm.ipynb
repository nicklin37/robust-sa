{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89deab47-cabd-4ed9-be52-9c6b463a2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a450bd-7c3c-46de-9140-91ea0d3391c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'../data/adversarial_swap_train_final.csv')\n",
    "df.head(5)\n",
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50c0be5c-a5ca-48d7-ad05-d139cd209a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13077,)\n",
      "(3270,)\n",
      "(13077,)\n",
      "(3270,)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(df['clean_text'], df['classification'], test_size=0.2)\n",
    "print(X_train_raw.shape)\n",
    "print(X_test_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "print(y_test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4f6a83f-db37-43f1-8686-72e760cef1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4698                                 free ice cream though\n",
      "9775     read lactose stuff hard eat cheese lactose jum...\n",
      "5270     lost favorite thing love always story year key...\n",
      "14465            hi selena made team support greece cyprus\n",
      "350                      stupid bipolar weather ruined day\n",
      "                               ...                        \n",
      "9316     yes haha impaled crossed key love scottishtryi...\n",
      "4884                                      hell awake early\n",
      "7362            monday work leg still hurting little smile\n",
      "6231        sometimes people never learn shut stop talking\n",
      "3285          thx old computer slow kubuntu blender really\n",
      "Name: clean_text, Length: 13077, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd3eb6d8-ef62-4ef0-b8d6-065817d29b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train_raw)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(X_train_raw)\n",
    "max_length = 23\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63f80012-dfd3-4523-aa22-1e72c1a30ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "vocab = []\n",
    "for x in X_train_raw:\n",
    "    x = x.split(' ')\n",
    "    for word in x:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "    X_train.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb885a01-4b45-453c-a3b7-c59bbc821ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd0985da-5e38-4066-a8ba-31073a32ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "15872 words loaded!\n"
     ]
    }
   ],
   "source": [
    "model = load_glove_model(\"output.txt\")\n",
    "dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2abbd0a-4eac-48f9-9247-1fa39c2a41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_dict(vocab):\n",
    "    # create a map of words to vectors\n",
    "    embedding = dict()\n",
    "    for word in vocab:\n",
    "        # key is string word, value is numpy array for vector\n",
    "        if word in model:\n",
    "            embedding[word] = np.asarray(model[word], dtype='float32')\n",
    "    return embedding\n",
    "\n",
    "def create_embedding_matrix(vocab_size, dim, vocab, embeddings_index):\n",
    "    embedding_matrix = np.zeros((vocab_size, 100))\n",
    "    for word, i in t.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_dict = create_embedding_dict(vocab)\n",
    "embedding_matrix = create_embedding_matrix(vocab_size, 100, vocab, embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3ea53-9441-421a-a87b-6156727ca5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(embedding_dict.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a65167d-deda-4166-93c6-0d1e068a09ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2175080f-5c75-44af-a674-651e49baa441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, dim):\n",
    "    custom_embedding_layer = layers.Embedding(vocab_size, dim, weights=[embedding_matrix], trainable=False, name=\"embeddings\")\n",
    "    model = keras.Sequential()\n",
    "    model.add(custom_embedding_layer)\n",
    "    model.add(layers.LSTM(100, dropout=0.3, name=\"Normal\"))\n",
    "    #model.add(layers.LSTM(2))\n",
    "    #model.add(layers.LSTM(32, kernel_regularizer=\"l1\"))\n",
    "    model.add(layers.Dense(10))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8a58ae1-8584-4232-88a7-ef7b97ad1503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embeddings (Embedding)       (None, None, 100)         1573600   \n",
      "_________________________________________________________________\n",
      "Normal (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,655,021\n",
      "Trainable params: 81,421\n",
      "Non-trainable params: 1,573,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f71ad34-6838-4ce2-bc68-bfc847894a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6448 - accuracy: 0.5865\n",
      "Epoch 2/20\n",
      "409/409 [==============================] - 4s 11ms/step - loss: 0.6460 - accuracy: 0.5803\n",
      "Epoch 3/20\n",
      "409/409 [==============================] - 5s 11ms/step - loss: 0.6463 - accuracy: 0.5832\n",
      "Epoch 4/20\n",
      "409/409 [==============================] - 4s 11ms/step - loss: 0.6454 - accuracy: 0.5834\n",
      "Epoch 5/20\n",
      "409/409 [==============================] - 4s 11ms/step - loss: 0.6413 - accuracy: 0.5893\n",
      "Epoch 6/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6427 - accuracy: 0.5823\n",
      "Epoch 7/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6456 - accuracy: 0.5836\n",
      "Epoch 8/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6439 - accuracy: 0.5874\n",
      "Epoch 9/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6422 - accuracy: 0.5929\n",
      "Epoch 10/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6434 - accuracy: 0.5861\n",
      "Epoch 11/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6432 - accuracy: 0.5858\n",
      "Epoch 12/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6434 - accuracy: 0.5904\n",
      "Epoch 13/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6431 - accuracy: 0.5828\n",
      "Epoch 14/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6429 - accuracy: 0.5833\n",
      "Epoch 15/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6426 - accuracy: 0.5900\n",
      "Epoch 16/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6410 - accuracy: 0.5897\n",
      "Epoch 17/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6416 - accuracy: 0.5907\n",
      "Epoch 18/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6416 - accuracy: 0.5876\n",
      "Epoch 19/20\n",
      "409/409 [==============================] - 5s 12ms/step - loss: 0.6401 - accuracy: 0.5903\n",
      "Epoch 20/20\n",
      "409/409 [==============================] - 5s 13ms/step - loss: 0.6412 - accuracy: 0.5926\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded_docs, y_train_raw, epochs=20)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece07713-861b-4aa5-b7b4-e5d26f83b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts(X_train_raw)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(X_train_raw)\n",
    "max_length = 23\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "result = model.predict()\n",
    "result = np.round(result).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d7764d6-e88f-4cf2-a05e-deed5d6ff8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.030817\n",
      "Loss: 63.465697\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, y_train_raw, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "print('Loss: %f' % (loss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "947bd335-b32b-48e6-8ea7-4bad81be52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_model(vocab_size, dim):\n",
    "    custom_embedding_layer = layers.Embedding(vocab_size, dim, weights=[embedding_matrix], trainable=False, name=\"embeddings\")\n",
    "    model = keras.Sequential()\n",
    "    model.add(custom_embedding_layer)\n",
    "    model.add(layers.LSTM(100, dropout=0.3, name=\"Normal\", return_sequences=True))\n",
    "    model.add(layers.LSTM(32, dropout=0.3, kernel_regularizer=\"l1\", name=\"Regularized\"))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "513431df-cefe-4fc7-88cd-4f6790110bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embeddings (Embedding)       (None, None, 100)         1573600   \n",
      "_________________________________________________________________\n",
      "Normal (LSTM)                (None, None, 100)         80400     \n",
      "_________________________________________________________________\n",
      "Regularized (LSTM)           (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,671,057\n",
      "Trainable params: 97,457\n",
      "Non-trainable params: 1,573,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sparse_model = build_sparse_model(vocab_size, dim)\n",
    "sparse_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcc5b9fa-8a37-4b42-a6cf-7ab28d9d06cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "409/409 [==============================] - 10s 18ms/step - loss: 2.1063 - accuracy: 0.5393\n",
      "Epoch 2/20\n",
      "409/409 [==============================] - 7s 17ms/step - loss: 0.6966 - accuracy: 0.5590\n",
      "Epoch 3/20\n",
      "409/409 [==============================] - 8s 19ms/step - loss: 0.6872 - accuracy: 0.5751\n",
      "Epoch 4/20\n",
      "409/409 [==============================] - 7s 18ms/step - loss: 0.6879 - accuracy: 0.5686\n",
      "Epoch 5/20\n",
      "409/409 [==============================] - 8s 19ms/step - loss: 0.6797 - accuracy: 0.5815\n",
      "Epoch 6/20\n",
      "409/409 [==============================] - 8s 18ms/step - loss: 0.6793 - accuracy: 0.5799\n",
      "Epoch 7/20\n",
      "409/409 [==============================] - 7s 18ms/step - loss: 0.6768 - accuracy: 0.5772\n",
      "Epoch 8/20\n",
      "409/409 [==============================] - 8s 19ms/step - loss: 0.6774 - accuracy: 0.5748\n",
      "Epoch 9/20\n",
      "409/409 [==============================] - 8s 19ms/step - loss: 0.6710 - accuracy: 0.5895\n",
      "Epoch 10/20\n",
      "409/409 [==============================] - 8s 19ms/step - loss: 0.6735 - accuracy: 0.5897\n",
      "Epoch 11/20\n",
      "409/409 [==============================] - 8s 20ms/step - loss: 0.6743 - accuracy: 0.5829\n",
      "Epoch 12/20\n",
      "409/409 [==============================] - 8s 20ms/step - loss: 0.6714 - accuracy: 0.5862\n",
      "Epoch 13/20\n",
      "409/409 [==============================] - 10s 24ms/step - loss: 0.6722 - accuracy: 0.5819\n",
      "Epoch 14/20\n",
      "409/409 [==============================] - 8s 20ms/step - loss: 0.6699 - accuracy: 0.5884\n",
      "Epoch 15/20\n",
      "409/409 [==============================] - 8s 20ms/step - loss: 0.6690 - accuracy: 0.5843\n",
      "Epoch 16/20\n",
      "409/409 [==============================] - 8s 20ms/step - loss: 0.6683 - accuracy: 0.5851\n",
      "Epoch 17/20\n",
      "409/409 [==============================] - 8s 19ms/step - loss: 0.6667 - accuracy: 0.5878\n",
      "Epoch 18/20\n",
      "409/409 [==============================] - 8s 19ms/step - loss: 0.6711 - accuracy: 0.5850\n",
      "Epoch 19/20\n",
      "409/409 [==============================] - 8s 21ms/step - loss: 0.6666 - accuracy: 0.5887\n",
      "Epoch 20/20\n",
      "409/409 [==============================] - 8s 19ms/step - loss: 0.6672 - accuracy: 0.5871\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "history = sparse_model.fit(padded_docs, y_train_raw, epochs=20)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95751ebb-b453-4687-a884-63414a5d0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.306107\n",
      "Loss: 65.015322\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = sparse_model.evaluate(padded_docs, y_train_raw, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "print('Loss: %f' % (loss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c80a3-f1f0-4782-a855-468d6b22e822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
