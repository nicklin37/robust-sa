{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95e79207-f473-4e31-9e92-4480782c93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01ecca88-07c5-4ec1-9d49-c8d16fe8d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'../data/adversarial_swap_train_final.csv')\n",
    "df.head(5)\n",
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1579c4c7-a991-4dc6-a632-46049a245295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13077,)\n",
      "(3270,)\n",
      "(13077,)\n",
      "(3270,)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(df['clean_text'], df['classification'], test_size=0.2)\n",
    "print(X_train_raw.shape)\n",
    "print(X_test_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "print(y_test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c05df99f-9826-4290-b607-4681a55bf9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7219            oh u get must lol mum still isnt convinced\n",
      "12531           coming myspaceee yr work though dnt bother\n",
      "2872         ftw awh im sorry im probably going thing haha\n",
      "8663                 love itthats going one new fave quote\n",
      "14453                               happy mother day mommy\n",
      "                               ...                        \n",
      "7775     yes chloe youtube may th made feel x better ha...\n",
      "5893     hey fused gaming fusedgaming forum delayed pm ...\n",
      "2916                  cant stop smiling im best mood right\n",
      "15690                                 woot woot super cool\n",
      "743                                               arm hurt\n",
      "Name: clean_text, Length: 13077, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1a3765d-5e37-4312-83ca-90396c440324",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train_raw)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(X_train_raw)\n",
    "max_length = 23\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e5fc31f1-1ff2-4961-b2c8-f571ec5c3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(train):\n",
    "    X_train = []\n",
    "    vocab = []\n",
    "    for x in train:\n",
    "        x = x.split(' ')\n",
    "        for word in x:\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "        X_train.append(x)\n",
    "    return X_train\n",
    "\n",
    "X_train_tokens = tokenize_data(X_train_raw)\n",
    "X_test_tokens = tokenize_data(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "141690a7-6a3d-4fcb-ae02-974e8afc9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = gensim.models.Word2Vec(X_train_tokens, window=5, min_count=1, seed=1)\n",
    "# dense_model.wv.save_word2vec_format('test.txt', binary=False)\n",
    "dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8616ccee-b82a-45c9-8249-b6c2ce7206d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(train_data, label_data, model):\n",
    "    n = 100\n",
    "    m = len(train_data)\n",
    "    X = np.zeros((m, n))\n",
    "    y = label_data\n",
    "    \n",
    "    ind = 0\n",
    "    for tokens in train_data:\n",
    "        vec = np.zeros((n))\n",
    "        count = 0\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                count += 1\n",
    "                vec += model.wv[token]\n",
    "        if count != 0:\n",
    "            vec = np.divide(vec, count)\n",
    "        X[ind] = vec\n",
    "        ind += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5a860d9-9abf-4f32-aff4-53f14eebd86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_data(X_train_tokens, y_train_raw, dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13b4dfcb-4a22-4557-a0c5-f6418fbcaf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13077, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f38262e-935f-4ed4-89d7-a1e43a613771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13077,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a9cdb81-13ae-49d7-b6e9-92b05e37acdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/1279154391.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_raw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_test, y_test = create_data(X_test, y_test_raw, dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09262eac-050c-4cc0-8e2c-b83bb5f78cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bb1098d-a8db-4bcb-9d32-fd7c132184b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "15872 words loaded!\n"
     ]
    }
   ],
   "source": [
    "sparse_model = load_glove_model(\"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e85006be-6ccb-4527-85e6-ada25ee236dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cyprus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/2695120966.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cyprus'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'cyprus'"
     ]
    }
   ],
   "source": [
    "print(sparse_model['cyprus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d7abe0c-0cb0-4164-b29a-d446fc3bff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_sparse(train_data, label_data, model):\n",
    "    n = 100\n",
    "    m = len(train_data)\n",
    "    X = np.zeros((m, n))\n",
    "    y = label_data\n",
    "    \n",
    "    ind = 0\n",
    "    for tokens in train_data:\n",
    "        vec = np.zeros((n))\n",
    "        count = 0\n",
    "        for token in tokens:\n",
    "            if token in model:\n",
    "                count += 1\n",
    "                vec += model[token]\n",
    "        if count != 0:\n",
    "            vec = np.divide(vec, count)\n",
    "        X[ind] = vec\n",
    "        ind += 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c49ed4a3-8086-4fd5-8507-2b4aba3c4ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_data_sparse(X_train_tokens, y_train_raw, sparse_model)\n",
    "X_test, y_test = create_data_sparse(X_test_tokens, y_test_raw, sparse_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9d8d1-1442-4d87-a2c5-d21b21ac0de8",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c59f2f-adda-44b0-9974-d11d5d93ca4a",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "359ad438-0844-47c6-813a-115e221f52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "827773bd-7b51-4932-af5b-c036ed8b3a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=800, random_state=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_model = AdaBoostClassifier(n_estimators=800, random_state = 1)\n",
    "ada_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11ee6eba-d590-4a17-b5bb-4fdc7f5cf727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6314984709480123\n",
      "0.6053062561415001\n"
     ]
    }
   ],
   "source": [
    "test_pred = ada_model.predict(X_test)\n",
    "print(accuracy_score(y_test, test_pred))\n",
    "print(f1_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a5086-51fc-423a-a7c8-c18c154f7e14",
   "metadata": {},
   "source": [
    "## Sparse Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c21fa526-adb5-4b5a-8ec7-b526a5e3a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fc1b0ba9-16f8-4b2e-b228-f30b83f0ba13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=7000, penalty='l1', random_state=0, solver='saga')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='saga', penalty='l1', max_iter=7000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b97b5c29-4791-4b65-8e75-949374a681aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5935779816513761\n",
      "0.5912027068594278\n"
     ]
    }
   ],
   "source": [
    "clf_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, clf_pred))\n",
    "print(f1_score(y_test, clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "de68aab8-d3cb-4736-ac62-a079c70d87a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sguna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=7000, penalty='none', random_state=0, solver='saga')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_orig = LogisticRegression(random_state=0, solver='saga', penalty='none', max_iter=7000)\n",
    "clf_orig.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9480aceb-ce8d-47cc-96a8-cd1997d0a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.591131498470948\n",
      "0.5900030665440049\n"
     ]
    }
   ],
   "source": [
    "clf_orig_pred = clf_orig.predict(X_test)\n",
    "print(accuracy_score(y_test, clf_orig_pred))\n",
    "print(f1_score(y_test, clf_orig_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
