{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89deab47-cabd-4ed9-be52-9c6b463a2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2a450bd-7c3c-46de-9140-91ea0d3391c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>classification</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bos bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>interview leave alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>son couldnt put release already bought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>feeding baby fun smile coo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16354</th>\n",
       "      <td>27474</td>\n",
       "      <td>enjoy ur night</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>enjoy ur night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16355</th>\n",
       "      <td>27475</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wish could come see u denver husband lost job ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16356</th>\n",
       "      <td>27476</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ive wondered rake client made clear net dont f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16357</th>\n",
       "      <td>27477</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yay good enjoy break probably need hectic week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16358</th>\n",
       "      <td>27478</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>worth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16358 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "0               1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "1               2                          my boss is bullying me...   \n",
       "2               3                     what interview! leave me alone   \n",
       "3               4   Sons of ****, why couldn`t they put them on t...   \n",
       "4               6  2am feedings for the baby are fun when he is a...   \n",
       "...           ...                                                ...   \n",
       "16354       27474                                     enjoy ur night   \n",
       "16355       27475   wish we could come see u on Denver  husband l...   \n",
       "16356       27476   I`ve wondered about rake to.  The client has ...   \n",
       "16357       27477   Yay good for both of you. Enjoy the break - y...   \n",
       "16358       27478                         But it was worth it  ****.   \n",
       "\n",
       "      sentiment  classification  \\\n",
       "0      negative             0.0   \n",
       "1      negative             0.0   \n",
       "2      negative             0.0   \n",
       "3      negative             0.0   \n",
       "4      positive             1.0   \n",
       "...         ...             ...   \n",
       "16354  positive             1.0   \n",
       "16355  negative             0.0   \n",
       "16356  negative             0.0   \n",
       "16357  positive             1.0   \n",
       "16358  positive             1.0   \n",
       "\n",
       "                                              clean_text  \n",
       "0                                sooo sad miss san diego  \n",
       "1                                           bos bullying  \n",
       "2                                  interview leave alone  \n",
       "3                 son couldnt put release already bought  \n",
       "4                             feeding baby fun smile coo  \n",
       "...                                                  ...  \n",
       "16354                                     enjoy ur night  \n",
       "16355  wish could come see u denver husband lost job ...  \n",
       "16356  ive wondered rake client made clear net dont f...  \n",
       "16357  yay good enjoy break probably need hectic week...  \n",
       "16358                                              worth  \n",
       "\n",
       "[16358 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'../data/adversarial_swap_train_final.csv')\n",
    "df.head(5)\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50c0be5c-a5ca-48d7-ad05-d139cd209a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13087,)\n",
      "(3272,)\n",
      "(13087,)\n",
      "(3272,)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(df['clean_text'], df['classification'], test_size=0.2)\n",
    "print(X_train_raw.shape)\n",
    "print(X_test_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "print(y_test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd3eb6d8-ef62-4ef0-b8d6-065817d29b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train_raw)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(X_train_raw)\n",
    "max_length = 23\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63f80012-dfd3-4523-aa22-1e72c1a30ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15796\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "vocab = []\n",
    "for x in X_train_raw:\n",
    "    x = x.split(' ')\n",
    "    for word in x:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "    X_train.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd0985da-5e38-4066-a8ba-31073a32ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(X_train, window=5, min_count=1, seed=1)\n",
    "dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2abbd0a-4eac-48f9-9247-1fa39c2a41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_dict(vocab):\n",
    "    # create a map of words to vectors\n",
    "    embedding = dict()\n",
    "    for word in vocab:\n",
    "        # key is string word, value is numpy array for vector\n",
    "        embedding[word] = np.asarray(model.wv[word], dtype='float32')\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def create_embedding_matrix(vocab_size, dim, vocab, embeddings_index):\n",
    "    embedding_matrix = np.zeros((vocab_size, 100))\n",
    "    for word, i in t.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_dict = create_embedding_dict(vocab)\n",
    "embedding_matrix = create_embedding_matrix(vocab_size, 100, vocab, embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2175080f-5c75-44af-a674-651e49baa441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, dim):\n",
    "    custom_embedding_layer = layers.Embedding(vocab_size, dim, weights=[embedding_matrix], trainable=False, name=\"embeddings\")\n",
    "    model = keras.Sequential()\n",
    "    model.add(custom_embedding_layer)\n",
    "    model.add(layers.LSTM(100, dropout=0.3, name=\"Normal\"))\n",
    "    #model.add(layers.LSTM(2))\n",
    "    #model.add(layers.LSTM(32, kernel_regularizer=\"l1\"))\n",
    "    model.add(layers.Dense(10))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a8a58ae1-8584-4232-88a7-ef7b97ad1503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embeddings (Embedding)       (None, None, 100)         1579700   \n",
      "_________________________________________________________________\n",
      "Normal (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,661,121\n",
      "Trainable params: 81,421\n",
      "Non-trainable params: 1,579,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f71ad34-6838-4ce2-bc68-bfc847894a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "409/409 [==============================] - 9s 17ms/step - loss: 0.6612 - accuracy: 0.5795\n",
      "Epoch 2/20\n",
      "409/409 [==============================] - 7s 18ms/step - loss: 0.6288 - accuracy: 0.6437\n",
      "Epoch 3/20\n",
      "409/409 [==============================] - 9s 23ms/step - loss: 0.6185 - accuracy: 0.6536\n",
      "Epoch 4/20\n",
      "409/409 [==============================] - 10s 24ms/step - loss: 0.6073 - accuracy: 0.6642\n",
      "Epoch 5/20\n",
      "409/409 [==============================] - 10s 25ms/step - loss: 0.5977 - accuracy: 0.6718\n",
      "Epoch 6/20\n",
      "409/409 [==============================] - 9s 23ms/step - loss: 0.5927 - accuracy: 0.6710\n",
      "Epoch 7/20\n",
      "409/409 [==============================] - 7s 18ms/step - loss: 0.5924 - accuracy: 0.6730\n",
      "Epoch 8/20\n",
      "409/409 [==============================] - 7s 17ms/step - loss: 0.5841 - accuracy: 0.6790\n",
      "Epoch 9/20\n",
      "409/409 [==============================] - 7s 18ms/step - loss: 0.5857 - accuracy: 0.6808\n",
      "Epoch 10/20\n",
      "409/409 [==============================] - 8s 20ms/step - loss: 0.5787 - accuracy: 0.6832\n",
      "Epoch 11/20\n",
      "409/409 [==============================] - 10s 25ms/step - loss: 0.5828 - accuracy: 0.6798\n",
      "Epoch 12/20\n",
      "409/409 [==============================] - 10s 24ms/step - loss: 0.5805 - accuracy: 0.6843\n",
      "Epoch 13/20\n",
      "409/409 [==============================] - 8s 18ms/step - loss: 0.5808 - accuracy: 0.6821\n",
      "Epoch 14/20\n",
      "409/409 [==============================] - 8s 20ms/step - loss: 0.5806 - accuracy: 0.6823\n",
      "Epoch 15/20\n",
      "409/409 [==============================] - 8s 19ms/step - loss: 0.5757 - accuracy: 0.6868\n",
      "Epoch 16/20\n",
      "409/409 [==============================] - 7s 18ms/step - loss: 0.5779 - accuracy: 0.6854\n",
      "Epoch 17/20\n",
      "409/409 [==============================] - 7s 18ms/step - loss: 0.5748 - accuracy: 0.6898\n",
      "Epoch 18/20\n",
      "409/409 [==============================] - 7s 18ms/step - loss: 0.5732 - accuracy: 0.6921\n",
      "Epoch 19/20\n",
      "409/409 [==============================] - 10s 25ms/step - loss: 0.5754 - accuracy: 0.6873\n",
      "Epoch 20/20\n",
      "409/409 [==============================] - 8s 20ms/step - loss: 0.5731 - accuracy: 0.6882\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded_docs, y_train_raw, epochs=20)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece07713-861b-4aa5-b7b4-e5d26f83b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts(X_train_raw)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(X_train_raw)\n",
    "max_length = 23\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "result = model.predict()\n",
    "result = np.round(result).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5d7764d6-e88f-4cf2-a05e-deed5d6ff8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.459235\n",
      "Loss: 55.650568\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, y_train_raw, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "print('Loss: %f' % (loss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "947bd335-b32b-48e6-8ea7-4bad81be52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_model(vocab_size, dim):\n",
    "    custom_embedding_layer = layers.Embedding(vocab_size, dim, weights=[embedding_matrix], trainable=False, name=\"embeddings\")\n",
    "    model = keras.Sequential()\n",
    "    model.add(custom_embedding_layer)\n",
    "    model.add(layers.LSTM(100, dropout=0.3, name=\"Normal\", return_sequences=True))\n",
    "    model.add(layers.LSTM(32, dropout=0.3, kernel_regularizer=\"l1\", name=\"Regularized\"))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "513431df-cefe-4fc7-88cd-4f6790110bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embeddings (Embedding)       (None, None, 100)         1579700   \n",
      "_________________________________________________________________\n",
      "Normal (LSTM)                (None, None, 100)         80400     \n",
      "_________________________________________________________________\n",
      "Regularized (LSTM)           (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,677,157\n",
      "Trainable params: 97,457\n",
      "Non-trainable params: 1,579,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sparse_model = build_sparse_model(vocab_size, dim)\n",
    "sparse_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bcc5b9fa-8a37-4b42-a6cf-7ab28d9d06cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "409/409 [==============================] - 16s 31ms/step - loss: 2.1048 - accuracy: 0.5607\n",
      "Epoch 2/20\n",
      "409/409 [==============================] - 11s 28ms/step - loss: 0.6680 - accuracy: 0.6351\n",
      "Epoch 3/20\n",
      "409/409 [==============================] - 12s 28ms/step - loss: 0.6445 - accuracy: 0.6575\n",
      "Epoch 4/20\n",
      "409/409 [==============================] - 12s 29ms/step - loss: 0.6293 - accuracy: 0.6636\n",
      "Epoch 5/20\n",
      "409/409 [==============================] - 12s 29ms/step - loss: 0.6170 - accuracy: 0.6732\n",
      "Epoch 6/20\n",
      "409/409 [==============================] - 12s 29ms/step - loss: 0.6169 - accuracy: 0.6733\n",
      "Epoch 7/20\n",
      "409/409 [==============================] - 12s 29ms/step - loss: 0.6140 - accuracy: 0.6768\n",
      "Epoch 8/20\n",
      "409/409 [==============================] - 12s 29ms/step - loss: 0.6143 - accuracy: 0.6777\n",
      "Epoch 9/20\n",
      "409/409 [==============================] - 12s 28ms/step - loss: 0.6073 - accuracy: 0.6806\n",
      "Epoch 10/20\n",
      "409/409 [==============================] - 12s 28ms/step - loss: 0.6064 - accuracy: 0.6782\n",
      "Epoch 11/20\n",
      "409/409 [==============================] - 12s 28ms/step - loss: 0.6015 - accuracy: 0.6853\n",
      "Epoch 12/20\n",
      "409/409 [==============================] - 11s 28ms/step - loss: 0.6055 - accuracy: 0.6811\n",
      "Epoch 13/20\n",
      "409/409 [==============================] - 12s 28ms/step - loss: 0.6018 - accuracy: 0.6759\n",
      "Epoch 14/20\n",
      "409/409 [==============================] - 12s 29ms/step - loss: 0.6005 - accuracy: 0.6887\n",
      "Epoch 15/20\n",
      "409/409 [==============================] - 12s 29ms/step - loss: 0.6018 - accuracy: 0.6837\n",
      "Epoch 16/20\n",
      "409/409 [==============================] - 11s 28ms/step - loss: 0.5973 - accuracy: 0.6895\n",
      "Epoch 17/20\n",
      "409/409 [==============================] - 12s 28ms/step - loss: 0.5992 - accuracy: 0.6855\n",
      "Epoch 18/20\n",
      "409/409 [==============================] - 12s 28ms/step - loss: 0.5970 - accuracy: 0.6879\n",
      "Epoch 19/20\n",
      "409/409 [==============================] - 11s 28ms/step - loss: 0.5956 - accuracy: 0.6880\n",
      "Epoch 20/20\n",
      "409/409 [==============================] - 11s 28ms/step - loss: 0.5963 - accuracy: 0.6833\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "history = sparse_model.fit(padded_docs, y_train_raw, epochs=20)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "95751ebb-b453-4687-a884-63414a5d0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.830670\n",
      "Loss: 59.267986\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = sparse_model.evaluate(padded_docs, y_train_raw, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "print('Loss: %f' % (loss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c80a3-f1f0-4782-a855-468d6b22e822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
