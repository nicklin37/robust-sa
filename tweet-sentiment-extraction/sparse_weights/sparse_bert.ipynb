{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sparse_weights.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1aDmujOohv0Pi2HyqrwAf8BMpIF5MRw8G","authorship_tag":"ABX9TyPFuC2HMY8Vmdwd5SQ/pTWB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5RAUBLKNpUUR","executionInfo":{"status":"ok","timestamp":1638847290371,"user_tz":480,"elapsed":331,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}}},"source":["import nltk\n","from nltk.corpus import treebank \n","from nltk.tree import Tree\n","import csv \n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import string\n","import re\n","import math\n","import sklearn\n","from sklearn.model_selection import train_test_split"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0A5wkPSq-R4","executionInfo":{"status":"ok","timestamp":1638826529938,"user_tz":480,"elapsed":9843,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}},"outputId":"58c54582-bb23-47e3-a879-51277c6bb509"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69CC2_tXrF2I","executionInfo":{"status":"ok","timestamp":1638847293643,"user_tz":480,"elapsed":434,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}},"outputId":"2379cf73-a53a-431a-cbf8-dc24056ec3ff"},"source":["!ls \"/content/drive/My Drive/Colab Notebooks/data\""],"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["adversarial_swap_train.csv  adversarial_swap_train_final.csv\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"qBU5d_KDpnHX","executionInfo":{"status":"ok","timestamp":1638847300196,"user_tz":480,"elapsed":519,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}},"outputId":"e2f5577c-3b6f-4862-8121-d00a97df5a05"},"source":["df = pd.read_csv(r\"/content/drive/My Drive/Colab Notebooks/data/adversarial_swap_train_final.csv\")\n","df.head(10)"],"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>classification</th>\n","      <th>clean_text</th>\n","      <th>further_clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","      <td>['sooo', 'sad', 'miss', 'san', 'diego']</td>\n","      <td>['sooo', 'sad', 'miss', 'san', 'diego']</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","      <td>['boss', 'bullying']</td>\n","      <td>['bos', 'bullying']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","      <td>['interview', 'leave', 'alone']</td>\n","      <td>['interview', 'leave', 'alone']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","      <td>['sons', 'couldnt', 'put', 'releases', 'alread...</td>\n","      <td>['son', 'couldnt', 'put', 'release', 'already'...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>2am feedings for the baby are fun when he is a...</td>\n","      <td>positive</td>\n","      <td>1.0</td>\n","      <td>['feedings', 'baby', 'fun', 'smiles', 'coos']</td>\n","      <td>['feeding', 'baby', 'fun', 'smile', 'coo']</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>9</td>\n","      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n","      <td>positive</td>\n","      <td>1.0</td>\n","      <td>['journey', 'wow', 'u', 'became', 'cooler', 'h...</td>\n","      <td>['journey', 'wow', 'u', 'became', 'cooler', 'h...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>11</td>\n","      <td>I really really like the song Love Story by Ta...</td>\n","      <td>positive</td>\n","      <td>1.0</td>\n","      <td>['really', 'really', 'like', 'song', 'love', '...</td>\n","      <td>['really', 'really', 'like', 'song', 'love', '...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>12</td>\n","      <td>My Sharpie is running DANGERously low on ink</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","      <td>['sharpie', 'running', 'dangerously', 'low', '...</td>\n","      <td>['sharpie', 'running', 'dangerously', 'low', '...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>13</td>\n","      <td>i want to go to music tonight but i lost my vo...</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","      <td>['want', 'go', 'music', 'tonight', 'lost', 'vo...</td>\n","      <td>['want', 'go', 'music', 'tonight', 'lost', 'vo...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>15</td>\n","      <td>Uh oh, I am sunburned</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","      <td>['uh', 'oh', 'sunburned']</td>\n","      <td>['uh', 'oh', 'sunburned']</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...                                 further_clean_text\n","0           1  ...            ['sooo', 'sad', 'miss', 'san', 'diego']\n","1           2  ...                                ['bos', 'bullying']\n","2           3  ...                    ['interview', 'leave', 'alone']\n","3           4  ...  ['son', 'couldnt', 'put', 'release', 'already'...\n","4           6  ...         ['feeding', 'baby', 'fun', 'smile', 'coo']\n","5           9  ...  ['journey', 'wow', 'u', 'became', 'cooler', 'h...\n","6          11  ...  ['really', 'really', 'like', 'song', 'love', '...\n","7          12  ...  ['sharpie', 'running', 'dangerously', 'low', '...\n","8          13  ...  ['want', 'go', 'music', 'tonight', 'lost', 'vo...\n","9          15  ...                          ['uh', 'oh', 'sunburned']\n","\n","[10 rows x 6 columns]"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"Ot69ysR_qmw9"},"source":["!pip3 install transformers\n","import transformers\n","from transformers import BertTokenizer\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V0t_wpJiri_7","executionInfo":{"status":"ok","timestamp":1638847316452,"user_tz":480,"elapsed":5662,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dD3kt9Urqjc","executionInfo":{"status":"ok","timestamp":1638847317847,"user_tz":480,"elapsed":324,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}}},"source":["def encode_for_bert(data, maximum_length):\n","    input_ids = []\n","    attention_masks = []\n","  \n","    for i in data:\n","        sentence = ' '.join(i)\n","        encoded = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=maximum_length, pad_to_max_length=True, return_attention_mask=True, truncation=True)\n","      \n","        input_ids.append(encoded['input_ids'])\n","        attention_masks.append(encoded['attention_mask'])\n","    \n","    return np.array(input_ids),np.array(attention_masks)"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l6FufhfLrr-8","executionInfo":{"status":"ok","timestamp":1638847334747,"user_tz":480,"elapsed":15601,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}},"outputId":"22556fe9-1be3-4174-fea4-61e119031871"},"source":["X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(df['further_clean_text'], df['classification'], test_size=0.2)\n","train_input_ids, train_attention_masks = encode_for_bert(X_train_raw, 23)\n","test_input_ids, test_attention_masks = encode_for_bert(X_test_raw, 23)"],"execution_count":85,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"zpWrnkYNrtwz","executionInfo":{"status":"ok","timestamp":1638847336182,"user_tz":480,"elapsed":292,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}}},"source":["def add_sparse_layers(bert_model):\n","    input_ids = tf.keras.Input(shape=(23,),dtype='int32')\n","    attention_masks = tf.keras.Input(shape=(23,),dtype='int32')\n","  \n","    output = bert_model([input_ids,attention_masks])\n","    output = output[1]\n","    output = tf.keras.layers.Dense(32, activation='relu', kernel_regularizer='l1')(output)\n","    output = tf.keras.layers.Dropout(0.2)(output)\n","    output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n","\n","    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n","    model.compile(Adam(lr=6e-6), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":659},"id":"eTugPQz8ryBT","executionInfo":{"status":"error","timestamp":1638847441175,"user_tz":480,"elapsed":12237,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}},"outputId":"a022f07c-5008-469d-9baa-d417793c44cd"},"source":["from transformers import TFBertModel\n","bert_model = TFBertModel.from_pretrained('bert-large-uncased')"],"execution_count":89,"outputs":[{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-89-6090b3727c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-large-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1465\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build the network with dummy inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build the network with dummy inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Error retrieving file {resolved_archive_file}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         )\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_embeds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             )\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"bert\" (type TFBertMainLayer).\n\nOOM when allocating tensor with shape[30522,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TruncatedNormal]\n\nCall arguments received:\n  • input_ids=tf.Tensor(shape=(3, 5), dtype=int32)\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False\n  • kwargs=<class 'inspect._empty'>"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-4N3OoNQrzvU","executionInfo":{"status":"ok","timestamp":1638845378240,"user_tz":480,"elapsed":4546,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}},"outputId":"e49399f8-9620-41fd-8fb0-c597ec99864f"},"source":["model = add_sparse_layers(bert_model)\n","model.summary()"],"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_17 (InputLayer)          [(None, 23)]         0           []                               \n","                                                                                                  \n"," input_18 (InputLayer)          [(None, 23)]         0           []                               \n","                                                                                                  \n"," tf_bert_model_1 (TFBertModel)  multiple             335141888   ['input_17[0][0]',               \n","                                                                  'input_18[0][0]']               \n","                                                                                                  \n"," dense_10 (Dense)               (None, 32)           32800       ['tf_bert_model_1[3][1]']        \n","                                                                                                  \n"," dropout_151 (Dropout)          (None, 32)           0           ['dense_10[0][0]']               \n","                                                                                                  \n"," dense_11 (Dense)               (None, 1)            33          ['dropout_151[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 335,174,721\n","Trainable params: 335,174,721\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":728},"id":"fYe8V4r2sk0c","executionInfo":{"status":"error","timestamp":1638845410273,"user_tz":480,"elapsed":25777,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}},"outputId":"e536b1d6-f9c1-4001-c0c7-f96b3c4dd7c2"},"source":["history = model.fit([train_input_ids,train_attention_masks], y_train_raw, validation_split=0.2, epochs=2,batch_size=10)"],"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n"]},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-78-b0838b40894c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_attention_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 816, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 639, in apply_gradients\n        self._create_all_weights(var_list)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 830, in _create_all_weights\n        self._create_slots(var_list)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py\", line 119, in _create_slots\n        self.add_slot(var, 'v')\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 920, in add_slot\n        initial_value=initial_value)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/initializers/initializers_v2.py\", line 144, in __call__\n        return tf.zeros(shape, dtype)\n\n    ResourceExhaustedError: OOM when allocating tensor with shape[4096,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n"]}]},{"cell_type":"code","metadata":{"id":"mGvw2O8BsoWT","executionInfo":{"status":"ok","timestamp":1638844703090,"user_tz":480,"elapsed":149295,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}}},"source":["result = model.predict([test_input_ids,test_attention_masks])\n","result = np.round(result).astype(int)"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"uj9y0C1c_vfA","executionInfo":{"status":"ok","timestamp":1638844954430,"user_tz":480,"elapsed":319,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}}},"source":["from sklearn.metrics import accuracy_score, f1_score"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bo486pVpAopt","executionInfo":{"status":"ok","timestamp":1638844955522,"user_tz":480,"elapsed":4,"user":{"displayName":"Nicholas Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12406294288117506054"}},"outputId":"1d09d874-9d27-4e7b-fd2f-1f4c763f9ba2"},"source":["print(accuracy_score(y_test_raw, result))\n","print(f1_score(y_test_raw, result))"],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5030562347188264\n","0.6693777958519723\n"]}]}]}